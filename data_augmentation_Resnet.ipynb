{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet with Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains my experiments with additional image preprocessing and data augmentation techniques. Specifically, I applied the Grey World and Histogram Equalization methods and fitted Resnet34 models on the resulting data. I have combined the code and output from previously 4 notebooks for easier viewing in one place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table of Contents\n",
    "\n",
    "I. Resnet34 on images on images preprocessed with Grey World\n",
    "\n",
    "II. Resnet34 on images preprocessed with Histogram Equalization\n",
    "\n",
    "III. Resnet34 on images preprocessed with Histogram Equalization + Grey World\n",
    "\n",
    "IV. Resnet34 with Grey World + Histogram Equalization as a random data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"/home/ubuntu/data/sandwich/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    im = cv2.imread(str(path))\n",
    "    return cv2.cvtColor(im, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def crop(im, r, c, target_r, target_c): return im[r:r+target_r, c:c+target_c]\n",
    "\n",
    "\n",
    "# random crop to the original size\n",
    "def random_crop(x, r_pix=8):\n",
    "    \"\"\" Returns a random crop\"\"\"\n",
    "    r, c,*_ = x.shape\n",
    "    r, c,*_ = x.shape\n",
    "    c_pix = round(r_pix*c/r)\n",
    "    rand_r = random.uniform(0, 1)\n",
    "    rand_c = random.uniform(0, 1)\n",
    "    start_r = np.floor(2*rand_r*r_pix).astype(int)\n",
    "    start_c = np.floor(2*rand_c*c_pix).astype(int)\n",
    "    return crop(x, start_r, start_c, r-2*r_pix, c-2*c_pix)\n",
    "\n",
    "def center_crop(x, r_pix=8):\n",
    "    r, c,*_ = x.shape\n",
    "    c_pix = round(r_pix*c/r)\n",
    "    return crop(x, r_pix, c_pix, r-2*r_pix, c-2*c_pix)\n",
    "\n",
    "\n",
    "def rotate_cv(im, deg, mode=cv2.BORDER_REFLECT, interpolation=cv2.INTER_AREA):\n",
    "    \"\"\" Rotates an image by deg degrees\"\"\"\n",
    "    r,c,*_ = im.shape\n",
    "    M = cv2.getRotationMatrix2D((c/2,r/2),deg,1)\n",
    "    return cv2.warpAffine(im,M,(c,r), borderMode=mode, \n",
    "                          flags=cv2.WARP_FILL_OUTLIERS+interpolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(path):\n",
    "    paths = [d for d in list(path.iterdir()) if d.is_dir()]\n",
    "    files = [f for d in paths for f in list(d.iterdir())]\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(im):\n",
    "    \"\"\"Normalizes images with Imagenet stats.\"\"\"\n",
    "    imagenet_stats = np.array([[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]])\n",
    "    return (im - imagenet_stats[0])/imagenet_stats[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SandwichDataset(Dataset):\n",
    "    def __init__(self, files, labels, transforms=False):\n",
    "        self.files = files\n",
    "        self.label2ind = {v:k for k,v in enumerate(labels)}\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.files[idx]\n",
    "        name = path.parts[-1]\n",
    "        y_class = self.label2ind[path.parts[-2]]\n",
    "        x = cv2.imread(str(path)).astype(np.float32)\n",
    "        x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)/255\n",
    "        if self.transforms:\n",
    "            rdeg = (np.random.random()-.50)*20\n",
    "            x = rotate_cv(x, rdeg)\n",
    "            if np.random.random() > 0.5: x = np.fliplr(x).copy()\n",
    "            x = random_crop(x)\n",
    "        else:\n",
    "            x = center_crop(x)\n",
    "        x = normalize(x)\n",
    "        y = self.label2ind[path.parts[-2]]\n",
    "        return np.rollaxis(x, 2), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet34(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = list(resnet.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AdaptiveAvgPool2d(output_size=(1, 1)),\n",
       " Linear(in_features=512, out_features=1000, bias=True)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Resnet, self).__init__()\n",
    "        resnet = models.resnet34(pretrained=True)\n",
    "        # freezing parameters\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        # convolutional layers of resnet34\n",
    "        layers = list(resnet.children())[:8]\n",
    "        self.top_model = nn.Sequential(*layers).cuda()\n",
    "        self.fc = nn.Linear(512, 6)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.top_model(x))\n",
    "        x = nn.AdaptiveAvgPool2d((1,1))(x)\n",
    "        x = x.view(x.shape[0], -1) # flattening \n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_metrics(model, valid_dl):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0 \n",
    "    for x, y in valid_dl:\n",
    "        batch = y.shape[0]\n",
    "        x = x.cuda().float()\n",
    "        y = y.cuda()\n",
    "        out = model(x)\n",
    "        _, pred = torch.max(out, 1)\n",
    "        correct += pred.eq(y).sum().item()\n",
    "        loss = F.cross_entropy(out, y)\n",
    "        sum_loss += batch*(loss.item())\n",
    "        total += batch\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr=0.01, wd=0.0):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optim = torch.optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    return optim\n",
    "\n",
    "def update_optimizer(optimizer, lr):\n",
    "    for i, param_group in enumerate(optimizer.param_groups):\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(m, p): torch.save(m.state_dict(), p)\n",
    "    \n",
    "def load_model(m, p): m.load_state_dict(torch.load(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path(\"/home/ubuntu/models/sandwich/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_trainable_attr(m, b=True):\n",
    "    for p in m.parameters(): p.requires_grad = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfreeze(model, l):\n",
    "    top_model = model.top_model\n",
    "    set_trainable_attr(top_model[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetV2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResnetV2, self).__init__()\n",
    "        self.resnet = models.resnet34(pretrained=True)\n",
    "        self.freeze()\n",
    "        layers = list(self.resnet.children())[:8]\n",
    "        self.groups = nn.ModuleList([nn.Sequential(*h) for h in [layers[:6], layers[6:]]]) # Define groups of layers\n",
    "        self.groups.append(nn.Linear(512, 6))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for group in self.groups[:2]: # Resnet layers\n",
    "            x = group(x)\n",
    "        x = F.relu(x)\n",
    "        x = nn.AdaptiveAvgPool2d((1,1))(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.groups[2](x) # Linear layer\n",
    "        return x\n",
    "    \n",
    "    def freeze(self): # Freeze all Resnet\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    def unfreeze(self, group_idx:int): # Unfreeze a group\n",
    "        group = self.groups[group_idx]\n",
    "        parameters = filter(lambda x: hasattr(x,'requires_grad'), group.parameters())\n",
    "        for p in parameters: \n",
    "            p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimizer(model, lr0):\n",
    "    param_groups = [list(model.groups[i].parameters()) for i in range(3)] # Different parameters groups for optimizer\n",
    "    params = [{'params':p, 'lr': lr} for p,lr in zip(param_groups, [lr0/9, lr0/3, lr0])] # Different learning rates for groups\n",
    "    return optim.Adam(params)\n",
    "\n",
    "def update_optimizer(optimizer, lr):\n",
    "    for i, param_group in enumerate(optimizer.param_groups):\n",
    "        param_group[\"lr\"] = lr\n",
    "\n",
    "def update_optimizer_group(optimizer, group_lrs):\n",
    "    for i, param_group in enumerate(optimizer.param_groups):\n",
    "        param_group[\"lr\"] = group_lrs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_segment(start_lr, end_lr, iterations):\n",
    "    i = np.arange(iterations)\n",
    "    c_i = 1 + np.cos(i*np.pi/iterations)\n",
    "    return end_lr + (start_lr - end_lr)/2 *c_i\n",
    "\n",
    "def get_cosine_triangular_lr(max_lr, iterations):\n",
    "    min_start, min_end = max_lr/25, max_lr/(25*1e4)\n",
    "    iter1 = int(0.3*iterations)\n",
    "    iter2 = iterations - iter1\n",
    "    segs = [cosine_segment(min_start, max_lr, iter1), cosine_segment(max_lr, min_end, iter2)]\n",
    "    return np.concatenate(segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Resnet34 on images preprocessed with Grey World"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = PATH/\"gw-train-315\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_labels = [p.parts[-2] for p in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files, valid_files, y_train, y_valid = train_test_split(files, file_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [d for d in list(path.iterdir()) if d.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [p.parts[-1] for p in paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = SandwichDataset(files=train_files, labels=labels, transforms=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ds = SandwichDataset(files=valid_files, labels=labels, transforms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.cuda().float()\n",
    "y = y.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize pre-trained model with frozen hidden layers, train with fixed learning rate for 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs=5, learning_rate=0.01):\n",
    "    optimzer = get_optimizer(model, lr=learning_rate, wd=0)\n",
    "    prev_val_acc = 0.0\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        for x, y in train_dl:\n",
    "            batch = y.shape[0]\n",
    "            x = x.cuda().float()\n",
    "            y = y.cuda()\n",
    "            out = model(x)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            optimzer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimzer.step()\n",
    "            total += batch\n",
    "            sum_loss += batch*(loss.item())\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl)\n",
    "        if i % 2 == 0:\n",
    "            print(\"train loss %.3f val loss %.3f val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))\n",
    "        if val_acc > prev_val_acc: \n",
    "            prev_val_acc = val_acc\n",
    "            if val_acc > 0.6:\n",
    "                path = \"{0}/initial_gw_resnet_{1:.0f}.pth\".format(model_path, 100*val_acc)\n",
    "                save_model(model, path)\n",
    "                print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.513 val loss 0.962 val accuracy 0.654\n",
      "/home/ubuntu/models/sandwich/initial_gw_resnet_65.pth\n",
      "/home/ubuntu/models/sandwich/initial_gw_resnet_66.pth\n",
      "train loss 0.837 val loss 0.988 val accuracy 0.652\n",
      "/home/ubuntu/models/sandwich/initial_gw_resnet_69.pth\n",
      "train loss 0.857 val loss 1.171 val accuracy 0.663\n",
      "/home/ubuntu/models/sandwich/initial_gw_resnet_73.pth\n",
      "train loss 0.836 val loss 0.853 val accuracy 0.714\n",
      "/home/ubuntu/models/sandwich/initial_gw_resnet_74.pth\n",
      "train loss 0.778 val loss 0.854 val accuracy 0.729\n"
     ]
    }
   ],
   "source": [
    "train(model, epochs=10, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfreeze top 2 hidden layers, train with lower learning rate for additional 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(model, model_path/\"initial_gw_resnet_74.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8291657037205167, 0.7377777777777778)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfreeze(model, 7)\n",
    "unfreeze(model, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2(model, epochs=5, learning_rate=0.01):\n",
    "    optimzer = get_optimizer(model, lr=learning_rate, wd=0)\n",
    "    prev_val_acc = 0.0\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        for x, y in train_dl:\n",
    "            batch = y.shape[0]\n",
    "            x = x.cuda().float()\n",
    "            y = y.cuda()\n",
    "            out = model(x)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            optimzer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimzer.step()\n",
    "            total += batch\n",
    "            sum_loss += batch*(loss.item())\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl)\n",
    "        if i % 2 == 0:\n",
    "            print(\"train loss %.3f val loss %.3f val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))\n",
    "        if val_acc > prev_val_acc: \n",
    "            prev_val_acc = val_acc\n",
    "            if val_acc > 0.73:\n",
    "                path = \"{0}/unfreeze_gw_resnet_{1:.0f}.pth\".format(model_path, 100*val_acc)\n",
    "                save_model(model, path)\n",
    "                print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.145 val loss 0.874 val accuracy 0.722\n",
      "train loss 0.545 val loss 0.668 val accuracy 0.780\n",
      "/home/ubuntu/models/sandwich/unfreeze_gw_resnet_78.pth\n",
      "train loss 0.376 val loss 1.178 val accuracy 0.694\n",
      "train loss 0.281 val loss 0.919 val accuracy 0.752\n",
      "train loss 0.218 val loss 0.786 val accuracy 0.789\n",
      "/home/ubuntu/models/sandwich/unfreeze_gw_resnet_79.pth\n",
      "train loss 0.185 val loss 0.745 val accuracy 0.809\n",
      "/home/ubuntu/models/sandwich/unfreeze_gw_resnet_81.pth\n",
      "/home/ubuntu/models/sandwich/unfreeze_gw_resnet_82.pth\n",
      "train loss 0.143 val loss 1.291 val accuracy 0.693\n",
      "train loss 0.114 val loss 0.982 val accuracy 0.746\n",
      "train loss 0.124 val loss 0.687 val accuracy 0.804\n",
      "train loss 0.093 val loss 0.851 val accuracy 0.802\n"
     ]
    }
   ],
   "source": [
    "train2(model, epochs=20, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(model, model_path/\"/home/ubuntu/models/sandwich/unfreeze_gw_resnet_82.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8151458816395866, 0.8188888888888889)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics(model, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate range test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_range_finder(model, train_dl, lr_low=1e-5, lr_high=0.1, epochs=5):\n",
    "    losses = []\n",
    "    p = model_path/\"resnet_tmp.pth\"\n",
    "    save_model(model, str(p))\n",
    "    iterations = epochs * len(train_dl)\n",
    "    delta = (lr_high - lr_low)/iterations\n",
    "    lrs = [lr_low + i*delta for i in range(iterations)]\n",
    "    model.train()\n",
    "    ind = 0\n",
    "    optimizer = get_optimizer(model, lr=lrs[0], wd=0.0)\n",
    "    for i in range(epochs):\n",
    "        for x, y in train_dl:\n",
    "            update_optimizer(optimizer, lr=lrs[ind])\n",
    "            x = x.cuda().float()\n",
    "            y = y.cuda()\n",
    "            out = model(x)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "            ind += 1\n",
    "            \n",
    "    load_model(model, str(p))\n",
    "    return lrs, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs, losses = LR_range_finder(model, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lrs, losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminative fine-tuning, gradual unfreezing, and 1-cycle triangular learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize model with groups of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResnetV2().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-cycle rate training, unfreeze top hidden layers for 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_triangular_policy2(model, train_dl, valid_dl, max_lr=0.05, epochs=10):\n",
    "    idx = 0\n",
    "    iterations = epochs*len(train_dl)\n",
    "    lrs = get_cosine_triangular_lr(max_lr, iterations)\n",
    "    optimizer = create_optimizer(model, lrs[0])\n",
    "    prev_val_acc = 0.0\n",
    "    for j in range(epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        for i, (x, y) in enumerate(train_dl):\n",
    "            lr = lrs[idx]\n",
    "            update_optimizer_group(optimizer, [lr/9, lr/3, lr]) # In each iteration, update group learning rates\n",
    "            batch = y.shape[0]\n",
    "            x = x.cuda().float()\n",
    "            y = y.cuda()\n",
    "            out = model(x)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            idx += 1\n",
    "            if idx == int(0.1*iterations):\n",
    "                model.unfreeze(1)\n",
    "                print(idx, \"unfreezing 1\")\n",
    "            total += batch\n",
    "            sum_loss += batch*(loss.item())\n",
    "        train_loss = sum_loss/total\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl)\n",
    "        print(\"train_loss %.3f val_loss %.3f val_acc %.3f\" % (train_loss, val_loss, val_acc))\n",
    "        if val_acc > prev_val_acc: \n",
    "            prev_val_acc = val_acc\n",
    "            if val_acc > 0.73:\n",
    "                path = \"{0}/ft_gw_resnet_{1:.0f}.pth\".format(model_path, 100*val_acc)\n",
    "                save_model(model, path)\n",
    "                print(path)\n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.9244559076097276, 0.1622222222222222)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 1.422 val_loss 1.042 val_acc 0.647\n",
      "train_loss 0.957 val_loss 1.016 val_acc 0.602\n",
      "216 unfreezing 1\n",
      "train_loss 0.912 val_loss 0.992 val_acc 0.678\n",
      "train_loss 2.015 val_loss 1.442 val_acc 0.400\n",
      "train_loss 1.317 val_loss 2.546 val_acc 0.311\n",
      "train_loss 1.115 val_loss 4.264 val_acc 0.553\n",
      "train_loss 1.169 val_loss 1.418 val_acc 0.528\n",
      "train_loss 0.967 val_loss 1.193 val_acc 0.581\n",
      "train_loss 0.808 val_loss 89.946 val_acc 0.422\n",
      "train_loss 0.797 val_loss 1.269 val_acc 0.638\n",
      "train_loss 0.705 val_loss 0.870 val_acc 0.716\n",
      "train_loss 0.653 val_loss 1.085 val_acc 0.658\n",
      "train_loss 0.587 val_loss 1.029 val_acc 0.672\n",
      "train_loss 0.536 val_loss 0.820 val_acc 0.730\n",
      "train_loss 0.501 val_loss 0.980 val_acc 0.710\n",
      "train_loss 0.464 val_loss 0.959 val_acc 0.721\n",
      "train_loss 0.436 val_loss 1.060 val_acc 0.707\n",
      "train_loss 0.411 val_loss 1.089 val_acc 0.709\n",
      "train_loss 0.380 val_loss 0.724 val_acc 0.782\n",
      "/home/ubuntu/models/sandwich/ft_gw_resnet_78.pth\n",
      "train_loss 0.319 val_loss 0.653 val_acc 0.802\n",
      "/home/ubuntu/models/sandwich/ft_gw_resnet_80.pth\n",
      "train_loss 0.249 val_loss 0.738 val_acc 0.800\n",
      "train_loss 0.213 val_loss 0.712 val_acc 0.811\n",
      "/home/ubuntu/models/sandwich/ft_gw_resnet_81.pth\n",
      "train_loss 0.208 val_loss 0.663 val_acc 0.808\n",
      "train_loss 0.176 val_loss 0.724 val_acc 0.816\n",
      "/home/ubuntu/models/sandwich/ft_gw_resnet_82.pth\n",
      "train_loss 0.153 val_loss 0.755 val_acc 0.802\n",
      "train_loss 0.136 val_loss 0.715 val_acc 0.813\n",
      "train_loss 0.098 val_loss 0.735 val_acc 0.818\n",
      "/home/ubuntu/models/sandwich/ft_gw_resnet_82.pth\n",
      "train_loss 0.086 val_loss 0.728 val_acc 0.826\n",
      "/home/ubuntu/models/sandwich/ft_gw_resnet_83.pth\n",
      "train_loss 0.071 val_loss 0.752 val_acc 0.823\n",
      "train_loss 0.073 val_loss 0.748 val_acc 0.824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07300818271728025"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_triangular_policy2(model, train_dl, valid_dl, max_lr=0.05, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResnetV2().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(model, model_path/\"ft_gw_resnet_83.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7284822397761874, 0.8255555555555556)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Resnet34 on images preprocessed with Histogram Equalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = PATH/\"he-train-315\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_labels = [p.parts[-2] for p in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files, valid_files, y_train, y_valid = train_test_split(files, file_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [d for d in list(path.iterdir()) if d.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [p.parts[-1] for p in paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = SandwichDataset(files=train_files, labels=labels, transforms=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ds = SandwichDataset(files=valid_files, labels=labels, transforms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.cuda().float()\n",
    "y = y.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize pre-trained model with frozen hidden layers, train model with fixed learning rate for 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs=5, learning_rate=0.01):\n",
    "    optimzer = get_optimizer(model, lr=learning_rate, wd=0)\n",
    "    prev_val_acc = 0.0\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        for x, y in train_dl:\n",
    "            batch = y.shape[0]\n",
    "            x = x.cuda().float()\n",
    "            y = y.cuda()\n",
    "            out = model(x)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            optimzer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimzer.step()\n",
    "            total += batch\n",
    "            sum_loss += batch*(loss.item())\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl)\n",
    "        if i % 2 == 0:\n",
    "            print(\"train loss %.3f val loss %.3f val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))\n",
    "        if val_acc > prev_val_acc: \n",
    "            prev_val_acc = val_acc\n",
    "            if val_acc > 0.6:\n",
    "                path = \"{0}/initial_he_resnet_{1:.0f}.pth\".format(model_path, 100*val_acc)\n",
    "                save_model(model, path)\n",
    "                print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.682 val loss 0.982 val accuracy 0.636\n",
      "/home/ubuntu/models/sandwich/initial_he_resnet_64.pth\n",
      "train loss 0.890 val loss 0.851 val accuracy 0.717\n",
      "/home/ubuntu/models/sandwich/initial_he_resnet_72.pth\n",
      "train loss 0.844 val loss 0.813 val accuracy 0.734\n",
      "/home/ubuntu/models/sandwich/initial_he_resnet_73.pth\n",
      "train loss 0.790 val loss 0.800 val accuracy 0.731\n",
      "train loss 0.786 val loss 0.892 val accuracy 0.690\n"
     ]
    }
   ],
   "source": [
    "train(model, epochs=10, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfreeze top 2 hidden layers, train with lower learning rate for additional 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(model, model_path/\"initial_he_resnet_73.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8128087818622589, 0.7344444444444445)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfreeze(model, 7)\n",
    "unfreeze(model, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2(model, epochs=5, learning_rate=0.01):\n",
    "    optimzer = get_optimizer(model, lr=learning_rate, wd=0)\n",
    "    prev_val_acc = 0.0\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        for x, y in train_dl:\n",
    "            batch = y.shape[0]\n",
    "            x = x.cuda().float()\n",
    "            y = y.cuda()\n",
    "            out = model(x)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            optimzer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimzer.step()\n",
    "            total += batch\n",
    "            sum_loss += batch*(loss.item())\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl)\n",
    "        if i % 2 == 0:\n",
    "            print(\"train loss %.3f val loss %.3f val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))\n",
    "        if val_acc > prev_val_acc: \n",
    "            prev_val_acc = val_acc\n",
    "            if val_acc > 0.73:\n",
    "                path = \"{0}/unfreeze_he_resnet_{1:.0f}.pth\".format(model_path, 100*val_acc)\n",
    "                save_model(model, path)\n",
    "                print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.140 val loss 0.854 val accuracy 0.707\n",
      "train loss 0.588 val loss 0.939 val accuracy 0.658\n",
      "train loss 0.419 val loss 0.938 val accuracy 0.693\n",
      "/home/ubuntu/models/sandwich/unfreeze_he_resnet_76.pth\n",
      "train loss 0.307 val loss 0.888 val accuracy 0.736\n",
      "train loss 0.260 val loss 0.697 val accuracy 0.796\n",
      "/home/ubuntu/models/sandwich/unfreeze_he_resnet_80.pth\n",
      "train loss 0.189 val loss 0.685 val accuracy 0.819\n",
      "/home/ubuntu/models/sandwich/unfreeze_he_resnet_82.pth\n",
      "train loss 0.155 val loss 1.026 val accuracy 0.741\n",
      "train loss 0.160 val loss 0.849 val accuracy 0.789\n",
      "train loss 0.123 val loss 1.079 val accuracy 0.723\n",
      "train loss 0.110 val loss 0.874 val accuracy 0.796\n"
     ]
    }
   ],
   "source": [
    "train2(model, epochs=20, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(model, model_path/\"/home/ubuntu/models/sandwich/unfreeze_he_resnet_82.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7747624334361818, 0.8077777777777778)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics(model, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminative fine-tuning, gradual unfreezing, and 1-cycle triangular learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize model with groups of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResnetV2().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-cycle rate training, unfreeze top hidden layers, train for 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_triangular_policy2(model, train_dl, valid_dl, max_lr=0.05, epochs=10):\n",
    "    idx = 0\n",
    "    iterations = epochs*len(train_dl)\n",
    "    lrs = get_cosine_triangular_lr(max_lr, iterations)\n",
    "    optimizer = create_optimizer(model, lrs[0])\n",
    "    prev_val_acc = 0.0\n",
    "    for j in range(epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        for i, (x, y) in enumerate(train_dl):\n",
    "            lr = lrs[idx]\n",
    "            update_optimizer_group(optimizer, [lr/9, lr/3, lr]) # In each iteration, update group learning rates\n",
    "            batch = y.shape[0]\n",
    "            x = x.cuda().float()\n",
    "            y = y.cuda()\n",
    "            out = model(x)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            idx += 1\n",
    "            if idx == int(0.1*iterations):\n",
    "                model.unfreeze(1)\n",
    "                print(idx, \"unfreezing 1\")\n",
    "            total += batch\n",
    "            sum_loss += batch*(loss.item())\n",
    "        train_loss = sum_loss/total\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl)\n",
    "        print(\"train_loss %.3f val_loss %.3f val_acc %.3f\" % (train_loss, val_loss, val_acc))\n",
    "        if val_acc > prev_val_acc: \n",
    "            prev_val_acc = val_acc\n",
    "            if val_acc > 0.73:\n",
    "                path = \"{0}/ft_he_resnet_{1:.0f}.pth\".format(model_path, 100*val_acc)\n",
    "                save_model(model, path)\n",
    "                print(path)\n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.9079475204149883, 0.11333333333333333)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 1.397 val_loss 0.988 val_acc 0.689\n",
      "train_loss 1.036 val_loss 1.000 val_acc 0.631\n",
      "216 unfreezing 1\n",
      "train_loss 1.077 val_loss 0.897 val_acc 0.670\n",
      "train_loss 2.127 val_loss 9.386 val_acc 0.196\n",
      "train_loss 1.388 val_loss 1.570 val_acc 0.441\n",
      "train_loss 1.110 val_loss 1.665 val_acc 0.450\n",
      "train_loss 1.015 val_loss 2.196 val_acc 0.463\n",
      "train_loss 0.958 val_loss 1.205 val_acc 0.596\n",
      "train_loss 0.857 val_loss 1.286 val_acc 0.647\n",
      "train_loss 0.770 val_loss 1.006 val_acc 0.697\n",
      "train_loss 0.729 val_loss 0.977 val_acc 0.673\n",
      "train_loss 0.673 val_loss 1.476 val_acc 0.612\n",
      "train_loss 0.586 val_loss 0.806 val_acc 0.729\n",
      "train_loss 0.559 val_loss 0.926 val_acc 0.711\n",
      "train_loss 0.525 val_loss 0.732 val_acc 0.769\n",
      "/home/ubuntu/models/sandwich/ft_he_resnet_77.pth\n",
      "train_loss 0.503 val_loss 0.755 val_acc 0.757\n",
      "train_loss 0.447 val_loss 0.729 val_acc 0.757\n",
      "train_loss 0.390 val_loss 0.827 val_acc 0.731\n",
      "train_loss 0.359 val_loss 0.787 val_acc 0.779\n",
      "/home/ubuntu/models/sandwich/ft_he_resnet_78.pth\n",
      "train_loss 0.318 val_loss 0.755 val_acc 0.776\n",
      "train_loss 0.274 val_loss 0.700 val_acc 0.800\n",
      "/home/ubuntu/models/sandwich/ft_he_resnet_80.pth\n",
      "train_loss 0.245 val_loss 0.708 val_acc 0.790\n",
      "train_loss 0.194 val_loss 0.781 val_acc 0.777\n",
      "train_loss 0.156 val_loss 0.740 val_acc 0.796\n",
      "train_loss 0.116 val_loss 0.731 val_acc 0.801\n",
      "/home/ubuntu/models/sandwich/ft_he_resnet_80.pth\n",
      "train_loss 0.104 val_loss 0.780 val_acc 0.806\n",
      "/home/ubuntu/models/sandwich/ft_he_resnet_81.pth\n",
      "train_loss 0.092 val_loss 0.746 val_acc 0.813\n",
      "/home/ubuntu/models/sandwich/ft_he_resnet_81.pth\n",
      "train_loss 0.067 val_loss 0.764 val_acc 0.816\n",
      "/home/ubuntu/models/sandwich/ft_he_resnet_82.pth\n",
      "train_loss 0.060 val_loss 0.793 val_acc 0.806\n",
      "train_loss 0.061 val_loss 0.781 val_acc 0.812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0605154422745626"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_triangular_policy2(model, train_dl, valid_dl, max_lr=0.05, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResnetV2().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(model, model_path/\"ft_he_resnet_82.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7643823739555147, 0.8155555555555556)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Resnet34 on images preprocessed with Histogram Equalization + Grey World"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = PATH/\"hewg-train-315\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_labels = [p.parts[-2] for p in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files, valid_files, y_train, y_valid = train_test_split(files, file_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = SandwichDataset(files=train_files, labels=labels, transforms=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ds = SandwichDataset(files=valid_files, labels=labels, transforms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.cuda().float()\n",
    "y = y.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize pre-trained model with frozen hidden layers, train with fixed learning rate for 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs=5, learning_rate=0.01):\n",
    "    optimzer = get_optimizer(model, lr=learning_rate, wd=0)\n",
    "    prev_val_acc = 0.0\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        for x, y in train_dl:\n",
    "            batch = y.shape[0]\n",
    "            x = x.cuda().float()\n",
    "            y = y.cuda()\n",
    "            out = model(x)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            optimzer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimzer.step()\n",
    "            total += batch\n",
    "            sum_loss += batch*(loss.item())\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl)\n",
    "        if i % 2 == 0:\n",
    "            print(\"train loss %.3f val loss %.3f val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))\n",
    "        if val_acc > prev_val_acc: \n",
    "            prev_val_acc = val_acc\n",
    "            if val_acc > 0.6:\n",
    "                path = \"{0}/initial_hewg_resnet_{1:.0f}.pth\".format(model_path, 100*val_acc)\n",
    "                save_model(model, path)\n",
    "                print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.529 val loss 0.924 val accuracy 0.676\n",
      "/home/ubuntu/models/sandwich/initial_hewg_resnet_68.pth\n",
      "train loss 0.882 val loss 0.848 val accuracy 0.701\n",
      "/home/ubuntu/models/sandwich/initial_hewg_resnet_70.pth\n",
      "train loss 0.927 val loss 0.855 val accuracy 0.710\n",
      "/home/ubuntu/models/sandwich/initial_hewg_resnet_71.pth\n",
      "train loss 0.803 val loss 0.851 val accuracy 0.700\n",
      "train loss 0.838 val loss 0.967 val accuracy 0.686\n"
     ]
    }
   ],
   "source": [
    "train(model, epochs=10, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfreeze top 2 hidden layers, train with lower learning rate for additional 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(model, model_path/\"initial_hewg_resnet_71.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8553838498062558, 0.71)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfreeze(model, 7)\n",
    "unfreeze(model, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2(model, epochs=5, learning_rate=0.01):\n",
    "    optimzer = get_optimizer(model, lr=learning_rate, wd=0)\n",
    "    prev_val_acc = 0.0\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        for x, y in train_dl:\n",
    "            batch = y.shape[0]\n",
    "            x = x.cuda().float()\n",
    "            y = y.cuda()\n",
    "            out = model(x)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            optimzer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimzer.step()\n",
    "            total += batch\n",
    "            sum_loss += batch*(loss.item())\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl)\n",
    "        if i % 2 == 0:\n",
    "            print(\"train loss %.3f val loss %.3f val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))\n",
    "        if val_acc > prev_val_acc: \n",
    "            prev_val_acc = val_acc\n",
    "            if val_acc > 0.71:\n",
    "                path = \"{0}/unfreeze_hewg_resnet_{1:.0f}.pth\".format(model_path, 100*val_acc)\n",
    "                save_model(model, path)\n",
    "                print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.216 val loss 0.944 val accuracy 0.671\n",
      "train loss 0.562 val loss 0.796 val accuracy 0.732\n",
      "/home/ubuntu/models/sandwich/unfreeze_hewg_resnet_73.pth\n",
      "/home/ubuntu/models/sandwich/unfreeze_hewg_resnet_75.pth\n",
      "train loss 0.385 val loss 0.665 val accuracy 0.780\n",
      "/home/ubuntu/models/sandwich/unfreeze_hewg_resnet_78.pth\n",
      "train loss 0.308 val loss 0.832 val accuracy 0.749\n",
      "train loss 0.240 val loss 0.844 val accuracy 0.773\n",
      "train loss 0.204 val loss 0.836 val accuracy 0.761\n",
      "train loss 0.139 val loss 0.943 val accuracy 0.768\n",
      "/home/ubuntu/models/sandwich/unfreeze_hewg_resnet_79.pth\n",
      "train loss 0.125 val loss 0.858 val accuracy 0.772\n",
      "train loss 0.111 val loss 0.883 val accuracy 0.778\n",
      "train loss 0.083 val loss 0.861 val accuracy 0.777\n",
      "/home/ubuntu/models/sandwich/unfreeze_hewg_resnet_82.pth\n"
     ]
    }
   ],
   "source": [
    "train2(model, epochs=20, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(model, model_path/\"/home/ubuntu/models/sandwich/unfreeze_hewg_resnet_82.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7238615949948629, 0.8211111111111111)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics(model, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminative fine-tuning, gradual unfreezing, and 1-cycle triangular learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize model with groups of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResnetV2().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-cycle rate training, unfreeze top hidden layers, train for 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_triangular_policy2(model, train_dl, valid_dl, max_lr=0.05, epochs=10):\n",
    "    idx = 0\n",
    "    iterations = epochs*len(train_dl)\n",
    "    lrs = get_cosine_triangular_lr(max_lr, iterations)\n",
    "    optimizer = create_optimizer(model, lrs[0])\n",
    "    prev_val_acc = 0.0\n",
    "    for j in range(epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        for i, (x, y) in enumerate(train_dl):\n",
    "            lr = lrs[idx]\n",
    "            update_optimizer_group(optimizer, [lr/9, lr/3, lr]) # In each iteration, update group learning rates\n",
    "            batch = y.shape[0]\n",
    "            x = x.cuda().float()\n",
    "            y = y.cuda()\n",
    "            out = model(x)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            idx += 1\n",
    "            if idx == int(0.1*iterations):\n",
    "                model.unfreeze(1)\n",
    "                print(idx, \"unfreezing 1\")\n",
    "            total += batch\n",
    "            sum_loss += batch*(loss.item())\n",
    "        train_loss = sum_loss/total\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl)\n",
    "        print(\"train_loss %.3f val_loss %.3f val_acc %.3f\" % (train_loss, val_loss, val_acc))\n",
    "        if val_acc > prev_val_acc: \n",
    "            prev_val_acc = val_acc\n",
    "            if val_acc > 0.71:\n",
    "                path = \"{0}/ft_hewg_resnet_{1:.0f}.pth\".format(model_path, 100*val_acc)\n",
    "                save_model(model, path)\n",
    "                print(path)\n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.875699394279056, 0.17222222222222222)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 1.430 val_loss 1.065 val_acc 0.650\n",
      "train_loss 1.034 val_loss 0.911 val_acc 0.681\n",
      "216 unfreezing 1\n",
      "train_loss 1.037 val_loss 1.255 val_acc 0.571\n",
      "train_loss 1.843 val_loss 1.433 val_acc 0.500\n",
      "train_loss 1.302 val_loss 1.505 val_acc 0.457\n",
      "train_loss 1.252 val_loss 224.853 val_acc 0.220\n",
      "train_loss 1.065 val_loss 2.609 val_acc 0.351\n",
      "train_loss 0.897 val_loss 1.179 val_acc 0.589\n",
      "train_loss 0.819 val_loss 1.554 val_acc 0.622\n",
      "train_loss 0.766 val_loss 0.850 val_acc 0.726\n",
      "/home/ubuntu/models/sandwich/ft_hewg_resnet_73.pth\n",
      "train_loss 0.741 val_loss 1.121 val_acc 0.640\n",
      "train_loss 0.710 val_loss 0.771 val_acc 0.746\n",
      "/home/ubuntu/models/sandwich/ft_hewg_resnet_75.pth\n",
      "train_loss 0.663 val_loss 1.112 val_acc 0.650\n",
      "train_loss 0.593 val_loss 0.764 val_acc 0.752\n",
      "/home/ubuntu/models/sandwich/ft_hewg_resnet_75.pth\n",
      "train_loss 0.534 val_loss 0.713 val_acc 0.773\n",
      "/home/ubuntu/models/sandwich/ft_hewg_resnet_77.pth\n",
      "train_loss 0.489 val_loss 0.770 val_acc 0.777\n",
      "/home/ubuntu/models/sandwich/ft_hewg_resnet_78.pth\n",
      "train_loss 0.458 val_loss 0.909 val_acc 0.712\n",
      "train_loss 0.381 val_loss 0.723 val_acc 0.766\n",
      "train_loss 0.347 val_loss 0.756 val_acc 0.776\n",
      "train_loss 0.302 val_loss 1.042 val_acc 0.727\n",
      "train_loss 0.269 val_loss 0.748 val_acc 0.771\n",
      "train_loss 0.223 val_loss 0.820 val_acc 0.753\n",
      "train_loss 0.199 val_loss 0.896 val_acc 0.774\n",
      "train_loss 0.156 val_loss 0.711 val_acc 0.810\n",
      "/home/ubuntu/models/sandwich/ft_hewg_resnet_81.pth\n",
      "train_loss 0.133 val_loss 0.710 val_acc 0.811\n",
      "/home/ubuntu/models/sandwich/ft_hewg_resnet_81.pth\n",
      "train_loss 0.116 val_loss 0.757 val_acc 0.818\n",
      "/home/ubuntu/models/sandwich/ft_hewg_resnet_82.pth\n",
      "train_loss 0.091 val_loss 0.759 val_acc 0.817\n",
      "train_loss 0.076 val_loss 0.756 val_acc 0.818\n",
      "train_loss 0.065 val_loss 0.764 val_acc 0.821\n",
      "/home/ubuntu/models/sandwich/ft_hewg_resnet_82.pth\n",
      "train_loss 0.071 val_loss 0.766 val_acc 0.822\n",
      "/home/ubuntu/models/sandwich/ft_hewg_resnet_82.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07116714126378712"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_triangular_policy2(model, train_dl, valid_dl, max_lr=0.05, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResnetV2().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(model, model_path/\"/home/ubuntu/models/sandwich/ft_hewg_resnet_82.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7655745827489429, 0.8222222222222222)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Resnet34 with Grey World + Histogram Equalization as a random data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorcorrect.algorithm as cca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gwhe_img(img):\n",
    "    img = cca.grey_world(img)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    img_y_cr_cb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "    y, cr, cb = cv2.split(img_y_cr_cb)\n",
    "    y_eq = cv2.equalizeHist(y)\n",
    "    img_y_cr_cb_eq = cv2.merge((y_eq, cr, cb))\n",
    "    img_rgb_eq = cv2.cvtColor(img_y_cr_cb_eq, cv2.COLOR_YCR_CB2BGR)\n",
    "    return cv2.cvtColor(img_rgb_eq, cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = PATH/\"train-315\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_labels = [p.parts[-2] for p in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files, valid_files, y_train, y_valid = train_test_split(files, file_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [d for d in list(path.iterdir()) if d.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [p.parts[-1] for p in paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SandwichDatasetGWHE(Dataset):\n",
    "    def __init__(self, files, labels, transforms=False):\n",
    "        self.files = files\n",
    "        self.label2ind = {v:k for k,v in enumerate(labels)}\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.files[idx]\n",
    "        name = path.parts[-1]\n",
    "        y_class = self.label2ind[path.parts[-2]] \n",
    "        x = cv2.imread(str(path)).astype(np.float32)\n",
    "        if self.transforms:\n",
    "            # Randomly apply Grey World and Histogram Equalization to image\n",
    "            if np.random.random() > 0.5: x = gwhe_img(x).copy()\n",
    "            x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)/255\n",
    "            rdeg = (np.random.random()-.50)*20\n",
    "            x = rotate_cv(x, rdeg)\n",
    "            if np.random.random() > 0.5: x = np.fliplr(x).copy()\n",
    "            x = random_crop(x)\n",
    "        else:\n",
    "            x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)/255\n",
    "            x = center_crop(x)\n",
    "        x = normalize(x)\n",
    "        y = self.label2ind[path.parts[-2]]\n",
    "        return np.rollaxis(x, 2), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = SandwichDatasetGWHE(files=train_files, labels=labels, transforms=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ds = SandwichDatasetGWHE(files=valid_files, labels=labels, transforms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.cuda().float()\n",
    "y = y.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize pre-trained model with frozen hidden layers, train with fixed learning rate for 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs=5, learning_rate=0.01):\n",
    "    optimzer = get_optimizer(model, lr=learning_rate, wd=0)\n",
    "    prev_val_acc = 0.0\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        for x, y in train_dl:\n",
    "            batch = y.shape[0]\n",
    "            x = x.cuda().float()\n",
    "            y = y.cuda()\n",
    "            out = model(x)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            optimzer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimzer.step()\n",
    "            total += batch\n",
    "            sum_loss += batch*(loss.item())\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl)\n",
    "        if i % 2 == 0:\n",
    "            print(\"train loss %.3f val loss %.3f val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))\n",
    "        if val_acc > prev_val_acc:\n",
    "            prev_val_acc = val_acc\n",
    "            if val_acc > 0.6:\n",
    "                path = \"{0}/initial_aug_resnet_{1:.0f}.pth\".format(model_path, 100*val_acc)\n",
    "                save_model(model, path)\n",
    "                print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.554 val loss 0.914 val accuracy 0.670\n",
      "/home/ubuntu/models/sandwich/initial_aug_resnet_67.pth\n",
      "/home/ubuntu/models/sandwich/initial_aug_resnet_69.pth\n",
      "train loss 0.942 val loss 0.853 val accuracy 0.698\n",
      "/home/ubuntu/models/sandwich/initial_aug_resnet_70.pth\n",
      "train loss 0.887 val loss 1.004 val accuracy 0.649\n",
      "/home/ubuntu/models/sandwich/initial_aug_resnet_73.pth\n",
      "train loss 0.814 val loss 0.720 val accuracy 0.754\n",
      "/home/ubuntu/models/sandwich/initial_aug_resnet_75.pth\n",
      "train loss 0.808 val loss 0.847 val accuracy 0.739\n"
     ]
    }
   ],
   "source": [
    "train(model, epochs=10, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfreeze top 2 hidden layers, train with lower learning rate for additional 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(model, model_path/\"initial_aug_resnet_75.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7203980055120256, 0.7544444444444445)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfreeze(model, 7)\n",
    "unfreeze(model, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2(model, epochs=5, learning_rate=0.01):\n",
    "    optimzer = get_optimizer(model, lr=learning_rate, wd=0)\n",
    "    prev_val_acc = 0.0\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        for x, y in train_dl:\n",
    "            batch = y.shape[0]\n",
    "            x = x.cuda().float()\n",
    "            y = y.cuda()\n",
    "            out = model(x)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            optimzer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimzer.step()\n",
    "            total += batch\n",
    "            sum_loss += batch*(loss.item())\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl)\n",
    "        if i % 2 == 0:\n",
    "            print(\"train loss %.3f val loss %.3f val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))\n",
    "        if val_acc > prev_val_acc: \n",
    "            prev_val_acc = val_acc\n",
    "            if val_acc > 0.75:\n",
    "                path = \"{0}/unfreeze_aug_resnet_{1:.0f}.pth\".format(model_path, 100*val_acc)\n",
    "                save_model(model, path)\n",
    "                print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.147 val loss 0.806 val accuracy 0.738\n",
      "train loss 0.583 val loss 0.887 val accuracy 0.706\n",
      "/home/ubuntu/models/sandwich/unfreeze_aug_resnet_76.pth\n",
      "train loss 0.426 val loss 0.750 val accuracy 0.763\n",
      "/home/ubuntu/models/sandwich/unfreeze_aug_resnet_77.pth\n",
      "train loss 0.333 val loss 0.777 val accuracy 0.773\n",
      "/home/ubuntu/models/sandwich/unfreeze_aug_resnet_79.pth\n",
      "train loss 0.240 val loss 1.349 val accuracy 0.688\n",
      "train loss 0.213 val loss 0.700 val accuracy 0.801\n",
      "/home/ubuntu/models/sandwich/unfreeze_aug_resnet_80.pth\n",
      "/home/ubuntu/models/sandwich/unfreeze_aug_resnet_82.pth\n",
      "train loss 0.173 val loss 0.758 val accuracy 0.790\n",
      "train loss 0.146 val loss 0.823 val accuracy 0.799\n",
      "/home/ubuntu/models/sandwich/unfreeze_aug_resnet_83.pth\n",
      "train loss 0.102 val loss 0.874 val accuracy 0.809\n",
      "train loss 0.149 val loss 0.834 val accuracy 0.799\n",
      "/home/ubuntu/models/sandwich/unfreeze_aug_resnet_84.pth\n"
     ]
    }
   ],
   "source": [
    "train2(model, epochs=20, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(model, model_path/\"/home/ubuntu/models/sandwich/unfreeze_aug_resnet_84.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.609929227994548, 0.8377777777777777)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics(model, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminative fine-tuning, gradual unfreezing, and 1-cycle triangular learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize model with groups of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResnetV2().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-cycle rate training, unfreeze top hidden layers, train for 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_triangular_policy2(model, train_dl, valid_dl, max_lr=0.05, epochs=10):\n",
    "    idx = 0\n",
    "    iterations = epochs*len(train_dl)\n",
    "    lrs = get_cosine_triangular_lr(max_lr, iterations)\n",
    "    optimizer = create_optimizer(model, lrs[0])\n",
    "    prev_val_acc = 0.0\n",
    "    for j in range(epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        for i, (x, y) in enumerate(train_dl):\n",
    "            lr = lrs[idx]\n",
    "            update_optimizer_group(optimizer, [lr/9, lr/3, lr]) # In each iteration, update group learning rates\n",
    "            batch = y.shape[0]\n",
    "            x = x.cuda().float()\n",
    "            y = y.cuda()\n",
    "            out = model(x)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            idx += 1\n",
    "            if idx == int(0.1*iterations):\n",
    "                model.unfreeze(1)\n",
    "                print(idx, \"unfreezing 1\")\n",
    "            total += batch\n",
    "            sum_loss += batch*(loss.item())\n",
    "        train_loss = sum_loss/total\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl)\n",
    "        print(\"train_loss %.3f val_loss %.3f val_acc %.3f\" % (train_loss, val_loss, val_acc))\n",
    "        if val_acc > prev_val_acc: \n",
    "            prev_val_acc = val_acc\n",
    "            if val_acc > 0.73:\n",
    "                path = \"{0}/ft_aug_resnet_{1:.0f}.pth\".format(model_path, 100*val_acc)\n",
    "                save_model(model, path)\n",
    "                print(path)\n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.9267942772971258, 0.14333333333333334)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 1.381 val_loss 0.952 val_acc 0.688\n",
      "train_loss 0.961 val_loss 0.945 val_acc 0.629\n",
      "216 unfreezing 1\n",
      "train_loss 0.981 val_loss 0.865 val_acc 0.689\n",
      "train_loss 2.271 val_loss 2.265 val_acc 0.287\n",
      "train_loss 1.390 val_loss 1.379 val_acc 0.510\n",
      "train_loss 1.419 val_loss 19.780 val_acc 0.309\n",
      "train_loss 1.239 val_loss 1.508 val_acc 0.492\n",
      "train_loss 0.990 val_loss 1.410 val_acc 0.534\n",
      "train_loss 0.911 val_loss 0.986 val_acc 0.709\n",
      "train_loss 0.843 val_loss 1.233 val_acc 0.563\n",
      "train_loss 0.789 val_loss 0.734 val_acc 0.744\n",
      "/home/ubuntu/models/sandwich/ft_aug_resnet_74.pth\n",
      "train_loss 0.735 val_loss 0.984 val_acc 0.674\n",
      "train_loss 0.661 val_loss 1.081 val_acc 0.674\n",
      "train_loss 0.612 val_loss 0.810 val_acc 0.728\n",
      "train_loss 0.585 val_loss 0.690 val_acc 0.789\n",
      "/home/ubuntu/models/sandwich/ft_aug_resnet_79.pth\n",
      "train_loss 0.567 val_loss 0.890 val_acc 0.718\n",
      "train_loss 0.565 val_loss 0.944 val_acc 0.713\n",
      "train_loss 0.466 val_loss 0.848 val_acc 0.761\n",
      "train_loss 0.455 val_loss 0.686 val_acc 0.779\n",
      "train_loss 0.391 val_loss 0.866 val_acc 0.768\n",
      "train_loss 0.376 val_loss 0.706 val_acc 0.798\n",
      "/home/ubuntu/models/sandwich/ft_aug_resnet_80.pth\n",
      "train_loss 0.298 val_loss 0.632 val_acc 0.818\n",
      "/home/ubuntu/models/sandwich/ft_aug_resnet_82.pth\n",
      "train_loss 0.279 val_loss 0.735 val_acc 0.793\n",
      "train_loss 0.242 val_loss 0.705 val_acc 0.811\n",
      "train_loss 0.201 val_loss 0.658 val_acc 0.830\n",
      "/home/ubuntu/models/sandwich/ft_aug_resnet_83.pth\n",
      "train_loss 0.177 val_loss 0.588 val_acc 0.830\n",
      "train_loss 0.156 val_loss 0.641 val_acc 0.823\n",
      "train_loss 0.132 val_loss 0.647 val_acc 0.836\n",
      "/home/ubuntu/models/sandwich/ft_aug_resnet_84.pth\n",
      "train_loss 0.122 val_loss 0.657 val_acc 0.836\n",
      "train_loss 0.121 val_loss 0.663 val_acc 0.836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12141090502134627"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_triangular_policy2(model, train_dl, valid_dl, max_lr=0.05, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResnetV2().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(model, model_path/\"ft_aug_resnet_84.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6474739015102386, 0.8355555555555556)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
