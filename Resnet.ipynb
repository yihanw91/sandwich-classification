{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"/home/ubuntu/data/sandwich/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list(PATH.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    im = cv2.imread(str(path))\n",
    "    return cv2.cvtColor(im, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def crop(im, r, c, target_r, target_c): return im[r:r+target_r, c:c+target_c]\n",
    "\n",
    "\n",
    "# random crop to the original size\n",
    "def random_crop(x, r_pix=8):\n",
    "    \"\"\" Returns a random crop\"\"\"\n",
    "    r, c,*_ = x.shape\n",
    "    r, c,*_ = x.shape\n",
    "    c_pix = round(r_pix*c/r)\n",
    "    rand_r = random.uniform(0, 1)\n",
    "    rand_c = random.uniform(0, 1)\n",
    "    start_r = np.floor(2*rand_r*r_pix).astype(int)\n",
    "    start_c = np.floor(2*rand_c*c_pix).astype(int)\n",
    "    return crop(x, start_r, start_c, r-2*r_pix, c-2*c_pix)\n",
    "\n",
    "def center_crop(x, r_pix=8):\n",
    "    r, c,*_ = x.shape\n",
    "    c_pix = round(r_pix*c/r)\n",
    "    return crop(x, r_pix, c_pix, r-2*r_pix, c-2*c_pix)\n",
    "\n",
    "\n",
    "def rotate_cv(im, deg, mode=cv2.BORDER_REFLECT, interpolation=cv2.INTER_AREA):\n",
    "    \"\"\" Rotates an image by deg degrees\"\"\"\n",
    "    r,c,*_ = im.shape\n",
    "    M = cv2.getRotationMatrix2D((c/2,r/2),deg,1)\n",
    "    return cv2.warpAffine(im,M,(c,r), borderMode=mode, \n",
    "                          flags=cv2.WARP_FILL_OUTLIERS+interpolation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(path):\n",
    "    paths = [d for d in list(path.iterdir()) if d.is_dir()]\n",
    "    files = [f for d in paths for f in list(d.iterdir())]\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=PATH/\"train-315\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_labels = [p.parts[-2] for p in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files, valid_files, y_train, y_valid = train_test_split(files, file_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter(y_train), Counter(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(im):\n",
    "    \"\"\"Normalizes images with Imagenet stats.\"\"\"\n",
    "    imagenet_stats = np.array([[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]])\n",
    "    return (im - imagenet_stats[0])/imagenet_stats[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [d for d in list(path.iterdir()) if d.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [p.parts[-1] for p in paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hot_dog',\n",
       " 'pulled_pork_sandwich',\n",
       " 'grilled_cheese_sandwich',\n",
       " 'lobster_roll_sandwich',\n",
       " 'hamburger',\n",
       " 'club_sandwich']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SandwichDataset(Dataset):\n",
    "    def __init__(self, files, labels, transforms=False):\n",
    "        self.files = files\n",
    "        self.label2ind = {v:k for k,v in enumerate(labels)}\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.files[idx]\n",
    "        name = path.parts[-1]\n",
    "        y_class = self.label2ind[path.parts[-2]]\n",
    "        x = cv2.imread(str(path)).astype(np.float32)\n",
    "        x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)/255\n",
    "        if self.transforms:\n",
    "            rdeg = (np.random.random()-.50)*20\n",
    "            x = rotate_cv(x, rdeg)\n",
    "            if np.random.random() > 0.5: x = np.fliplr(x).copy()\n",
    "            x = random_crop(x)\n",
    "        else:\n",
    "            x = center_crop(x)\n",
    "        x = normalize(x)\n",
    "        y = self.label2ind[path.parts[-2]]\n",
    "        return np.rollaxis(x, 2), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = SandwichDataset(files=train_files, labels=labels, transforms=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ds = SandwichDataset(files=valid_files, labels=labels, transforms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 299, 299), 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.cuda().float()\n",
    "y = y.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize pre-trained model with frozen hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet34(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = list(resnet.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AdaptiveAvgPool2d(output_size=(1, 1)),\n",
       " Linear(in_features=512, out_features=1000, bias=True)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Resnet, self).__init__()\n",
    "        resnet = models.resnet34(pretrained=True)\n",
    "        # freezing parameters\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        # convolutional layers of resnet34\n",
    "        layers = list(resnet.children())[:8]\n",
    "        self.top_model = nn.Sequential(*layers).cuda()\n",
    "        self.fc = nn.Linear(512, 6)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.top_model(x))\n",
    "        x = nn.AdaptiveAvgPool2d((1,1))(x)\n",
    "        x = x.view(x.shape[0], -1) # flattening \n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Resnet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_features = model.top_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_features_ave = nn.AdaptiveAvgPool2d((1,1))(x_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# x_features_ave.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_features_ave.size(0), x_features_ave.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_features_flatten = x_features_ave.view(x_features_ave.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_features_flatten.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, pred = torch.max(out, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred.eq(y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9382858276367188"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(out, y).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_metrics(model, valid_dl):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0 \n",
    "    for x, y in valid_dl:\n",
    "        batch = y.shape[0]\n",
    "        x = x.cuda().float()\n",
    "        y = y.cuda()\n",
    "        out = model(x)\n",
    "        _, pred = torch.max(out, 1)\n",
    "        correct += pred.eq(y).sum().item()\n",
    "        loss = F.cross_entropy(out, y)\n",
    "        sum_loss += batch*(loss.item())\n",
    "        total += batch\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.985863486925761, 0.16444444444444445)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics(model, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model with fixed learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr=0.01, wd=0.0):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optim = torch.optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    return optim\n",
    "\n",
    "def update_optimizer(optimizer, lr):\n",
    "    for i, param_group in enumerate(optimizer.param_groups):\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs=5, learning_rate=0.01):\n",
    "    optimzer = get_optimizer(model, lr=learning_rate, wd=0)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        prev_val_acc = 0.0\n",
    "        for x, y in train_dl:\n",
    "            batch = y.shape[0]\n",
    "            x = x.cuda().float()\n",
    "            y = y.cuda()\n",
    "            out = model(x)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            optimzer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimzer.step()\n",
    "            total += batch\n",
    "            sum_loss += batch*(loss.item())\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl)\n",
    "        if i % 2 == 0:\n",
    "            print(\"train loss %.3f val loss %.3f val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))\n",
    "        if val_acc > prev_val_acc: \n",
    "            prev_val_acc = val_acc\n",
    "            if val_acc > 0.8:\n",
    "                path = \"{0}/ft_resnet_loss_{1:.0f}.pth\".format(model_path, 100*val_acc)\n",
    "                save_model(model, path)\n",
    "                print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.498 val loss 0.806 val accuracy 0.717\n",
      "train loss 0.772 val loss 0.853 val accuracy 0.681\n",
      "train loss 0.811 val loss 0.838 val accuracy 0.724\n",
      "train loss 0.787 val loss 1.001 val accuracy 0.701\n",
      "train loss 0.737 val loss 0.849 val accuracy 0.710\n"
     ]
    }
   ],
   "source": [
    "train(model, epochs=10, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(m, p): torch.save(m.state_dict(), p)\n",
    "    \n",
    "def load_model(m, p): m.load_state_dict(torch.load(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path(\"/home/ubuntu/models/sandwich/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, model_path/\"initial_resnet.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unfreeze top layers, train with lower learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(model, model_path/\"initial_resnet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.798882888423072, 0.7488888888888889)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_trainable_attr(m, b=True):\n",
    "    for p in m.parameters(): p.requires_grad = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfreeze(model, l):\n",
    "    top_model = model.top_model\n",
    "    set_trainable_attr(top_model[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfreeze(model, 7)\n",
    "unfreeze(model, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.293 val loss 0.893 val accuracy 0.679\n",
      "train loss 0.478 val loss 0.737 val accuracy 0.758\n",
      "train loss 0.363 val loss 0.794 val accuracy 0.761\n",
      "train loss 0.264 val loss 0.572 val accuracy 0.812\n",
      "/home/ubuntu/models/sandwich/ft_resnet_loss_81.pth\n",
      "train loss 0.176 val loss 1.091 val accuracy 0.771\n",
      "train loss 0.178 val loss 0.695 val accuracy 0.810\n",
      "/home/ubuntu/models/sandwich/ft_resnet_loss_81.pth\n",
      "train loss 0.128 val loss 0.887 val accuracy 0.769\n",
      "train loss 0.095 val loss 0.855 val accuracy 0.786\n",
      "train loss 0.117 val loss 1.215 val accuracy 0.750\n",
      "/home/ubuntu/models/sandwich/ft_resnet_loss_80.pth\n",
      "train loss 0.088 val loss 0.776 val accuracy 0.812\n",
      "/home/ubuntu/models/sandwich/ft_resnet_loss_81.pth\n",
      "/home/ubuntu/models/sandwich/ft_resnet_loss_80.pth\n"
     ]
    }
   ],
   "source": [
    "train(model, epochs=20, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, model_path/\"initial_unfreeze_resnet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(model, model_path/\"initial_unfreeze_resnet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8814398679468367, 0.8022222222222222)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics(model, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate range test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_range_finder(model, train_dl, lr_low=1e-5, lr_high=0.1, epochs=5):\n",
    "    losses = []\n",
    "    p = model_path/\"resnet_tmp.pth\"\n",
    "    save_model(model, str(p))\n",
    "    iterations = epochs * len(train_dl)\n",
    "    delta = (lr_high - lr_low)/iterations\n",
    "    lrs = [lr_low + i*delta for i in range(iterations)]\n",
    "    model.train()\n",
    "    ind = 0\n",
    "    optimizer = get_optimizer(model, lr=lrs[0], wd=0.0)\n",
    "    for i in range(epochs):\n",
    "        for x, y in train_dl:\n",
    "            update_optimizer(optimizer, lr=lrs[ind])\n",
    "            x = x.cuda().float()\n",
    "            y = y.cuda()\n",
    "            out = model(x)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "            ind += 1\n",
    "            \n",
    "    load_model(model, str(p))\n",
    "    return lrs, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs, losses = LR_range_finder(model, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lrs, losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminative fine-tuning, gradual unfreezing, and 1-cycle triangular learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize model with groups of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetV2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResnetV2, self).__init__()\n",
    "        self.resnet = models.resnet34(pretrained=True)\n",
    "        self.freeze()\n",
    "        layers = list(self.resnet.children())[:8]\n",
    "        self.groups = nn.ModuleList([nn.Sequential(*h) for h in [layers[:6], layers[6:]]]) # Define groups of layers\n",
    "        self.groups.append(nn.Linear(512, 6))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for group in self.groups[:2]: # Resnet layers\n",
    "            x = group(x)\n",
    "        x = F.relu(x)\n",
    "        x = nn.AdaptiveAvgPool2d((1,1))(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.groups[2](x) # Linear layer\n",
    "        return x\n",
    "    \n",
    "    def freeze(self): # Freeze all Resnet\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    def unfreeze(self, group_idx:int): # Unfreeze a group\n",
    "        group = self.groups[group_idx]\n",
    "        parameters = filter(lambda x: hasattr(x,'requires_grad'), group.parameters())\n",
    "        for p in parameters: \n",
    "            p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimizer(model, lr0):\n",
    "    param_groups = [list(model.groups[i].parameters()) for i in range(3)] # Different parameters groups for optimizer\n",
    "    params = [{'params':p, 'lr': lr} for p,lr in zip(param_groups, [lr0/9, lr0/3, lr0])] # Different learning rates for groups\n",
    "    return optim.Adam(params)\n",
    "\n",
    "def update_optimizer(optimizer, group_lrs):\n",
    "    for i, param_group in enumerate(optimizer.param_groups):\n",
    "        param_group[\"lr\"] = group_lrs[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-cycle rate training, unfreeze all hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_segment(start_lr, end_lr, iterations):\n",
    "    i = np.arange(iterations)\n",
    "    c_i = 1 + np.cos(i*np.pi/iterations)\n",
    "    return end_lr + (start_lr - end_lr)/2 *c_i\n",
    "\n",
    "def get_cosine_triangular_lr(max_lr, iterations):\n",
    "    min_start, min_end = max_lr/25, max_lr/(25*1e4)\n",
    "    iter1 = int(0.3*iterations)\n",
    "    iter2 = iterations - iter1\n",
    "    segs = [cosine_segment(min_start, max_lr, iter1), cosine_segment(max_lr, min_end, iter2)]\n",
    "    return np.concatenate(segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_triangular_policy(model, train_dl, valid_dl, max_lr=0.06, epochs=10):\n",
    "    idx = 0\n",
    "    iterations = epochs*len(train_dl)\n",
    "    lrs = get_cosine_triangular_lr(max_lr, iterations)\n",
    "    optimizer = create_optimizer(model, lrs[0])\n",
    "    prev_val_acc = 0.0\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        for i, (x, y) in enumerate(train_dl):\n",
    "            lr = lrs[idx]\n",
    "            update_optimizer(optimizer, [lr/9, lr/3, lr]) # In each iteration, update group learning rates\n",
    "            batch = y.shape[0]\n",
    "            x = x.cuda().float()\n",
    "            y = y.cuda()\n",
    "            out = model(x)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            idx += 1\n",
    "            if idx == int(0.1*iterations):\n",
    "                model.unfreeze(1)\n",
    "                print(idx, \"unfreezing 1\")\n",
    "            if idx == int(0.2*iterations):\n",
    "                model.unfreeze(0)\n",
    "                print(idx, \"unfreezing 0\")\n",
    "            total += batch\n",
    "            sum_loss += batch*(loss.item())\n",
    "        train_loss = sum_loss/total\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl)\n",
    "        print(\"train_loss %.3f val_loss %.3f val_acc %.3f\" % (train_loss, val_loss, val_acc))\n",
    "        if val_acc > prev_val_acc: \n",
    "            prev_val_acc = val_acc\n",
    "            if val_acc > 0.8:\n",
    "                path = \"{0}/ft_resnet_loss_{1:.0f}.pth\".format(model_path, 100*val_acc)\n",
    "                save_model(model, path)\n",
    "                print(path)\n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResnetV2().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.9074531859821744, 0.13111111111111112)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 1.354 val_loss 0.993 val_acc 0.654\n",
      "train_loss 0.926 val_loss 0.831 val_acc 0.674\n",
      "216 unfreezing 1\n",
      "train_loss 0.922 val_loss 1.230 val_acc 0.598\n",
      "train_loss 2.038 val_loss 3.345 val_acc 0.266\n",
      "train_loss 1.407 val_loss 2.358 val_acc 0.404\n",
      "432 unfreezing 0\n",
      "train_loss 1.140 val_loss 1.846 val_acc 0.420\n",
      "train_loss 2.021 val_loss 1.848 val_acc 0.161\n",
      "train_loss 1.810 val_loss 1.822 val_acc 0.180\n",
      "train_loss 1.795 val_loss 1.786 val_acc 0.178\n",
      "train_loss 1.783 val_loss 2.048 val_acc 0.181\n",
      "train_loss 1.748 val_loss 1.858 val_acc 0.260\n",
      "train_loss 1.726 val_loss 1.760 val_acc 0.230\n",
      "train_loss 1.711 val_loss 1.750 val_acc 0.253\n",
      "train_loss 1.708 val_loss 1.728 val_acc 0.276\n",
      "train_loss 1.682 val_loss 1.765 val_acc 0.260\n",
      "train_loss 1.665 val_loss 1.725 val_acc 0.252\n",
      "train_loss 1.655 val_loss 1.933 val_acc 0.296\n",
      "train_loss 1.624 val_loss 1.728 val_acc 0.287\n",
      "train_loss 1.584 val_loss 1.627 val_acc 0.356\n",
      "train_loss 1.538 val_loss 1.783 val_acc 0.294\n",
      "train_loss 1.505 val_loss 1.615 val_acc 0.324\n",
      "train_loss 1.447 val_loss 1.523 val_acc 0.388\n",
      "train_loss 1.409 val_loss 1.544 val_acc 0.399\n",
      "train_loss 1.365 val_loss 1.466 val_acc 0.438\n",
      "train_loss 1.281 val_loss 1.457 val_acc 0.442\n",
      "train_loss 1.212 val_loss 1.305 val_acc 0.497\n",
      "train_loss 1.158 val_loss 1.420 val_acc 0.462\n",
      "train_loss 1.102 val_loss 1.219 val_acc 0.556\n",
      "train_loss 1.054 val_loss 1.203 val_acc 0.564\n",
      "train_loss 1.033 val_loss 1.201 val_acc 0.569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0330154771606128"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_triangular_policy(model, train_dl, valid_dl, max_lr=0.06, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-cycle rate training, unfreeze top hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_triangular_policy2(model, train_dl, valid_dl, max_lr=0.06, epochs=10):\n",
    "    idx = 0\n",
    "    iterations = epochs*len(train_dl)\n",
    "    lrs = get_cosine_triangular_lr(max_lr, iterations)\n",
    "    optimizer = create_optimizer(model, lrs[0])\n",
    "    prev_val_acc = 0.0\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        for i, (x, y) in enumerate(train_dl):\n",
    "            lr = lrs[idx]\n",
    "            update_optimizer(optimizer, [lr/9, lr/3, lr]) # In each iteration, update group learning rates\n",
    "            batch = y.shape[0]\n",
    "            x = x.cuda().float()\n",
    "            y = y.cuda()\n",
    "            out = model(x)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            idx += 1\n",
    "            if idx == int(0.1*iterations):\n",
    "                model.unfreeze(1)\n",
    "                print(idx, \"unfreezing 1\")\n",
    "#             if idx == int(0.2*iterations):\n",
    "#                 model.unfreeze(0)\n",
    "#                 print(idx, \"unfreezing 0\")\n",
    "            total += batch\n",
    "            sum_loss += batch*(loss.item())\n",
    "        train_loss = sum_loss/total\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl)\n",
    "        print(\"train_loss %.3f val_loss %.3f val_acc %.3f\" % (train_loss, val_loss, val_acc))\n",
    "        if val_acc > prev_val_acc: \n",
    "            prev_val_acc = val_acc\n",
    "            if val_acc > 0.8:\n",
    "                path = \"{0}/ft_resnet_loss_{1:.0f}.pth\".format(model_path, 100*val_acc)\n",
    "                save_model(model, path)\n",
    "                print(path)\n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResnetV2().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.9448052909639146, 0.14555555555555555)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 1.337 val_loss 1.000 val_acc 0.636\n",
      "train_loss 0.929 val_loss 0.852 val_acc 0.698\n",
      "216 unfreezing 1\n",
      "train_loss 1.041 val_loss 1.015 val_acc 0.686\n",
      "train_loss 2.133 val_loss 1.690 val_acc 0.362\n",
      "train_loss 1.505 val_loss 232.954 val_acc 0.150\n",
      "train_loss 1.311 val_loss 1.286 val_acc 0.534\n",
      "train_loss 1.018 val_loss 1.309 val_acc 0.554\n",
      "train_loss 0.890 val_loss 1.083 val_acc 0.643\n",
      "train_loss 0.809 val_loss 1.038 val_acc 0.616\n",
      "train_loss 0.736 val_loss 0.851 val_acc 0.729\n",
      "train_loss 0.681 val_loss 1.183 val_acc 0.636\n",
      "train_loss 0.601 val_loss 0.826 val_acc 0.743\n",
      "train_loss 0.551 val_loss 0.860 val_acc 0.729\n",
      "train_loss 0.507 val_loss 0.995 val_acc 0.693\n",
      "train_loss 0.488 val_loss 1.024 val_acc 0.681\n",
      "train_loss 0.416 val_loss 0.894 val_acc 0.749\n",
      "train_loss 0.426 val_loss 0.809 val_acc 0.727\n",
      "train_loss 0.359 val_loss 0.787 val_acc 0.763\n",
      "train_loss 0.329 val_loss 0.729 val_acc 0.780\n",
      "train_loss 0.283 val_loss 0.928 val_acc 0.767\n",
      "train_loss 0.247 val_loss 0.838 val_acc 0.791\n",
      "train_loss 0.223 val_loss 0.857 val_acc 0.771\n",
      "train_loss 0.183 val_loss 0.630 val_acc 0.819\n",
      "/home/ubuntu/models/sandwich/ft_resnet_loss_82.pth\n",
      "train_loss 0.136 val_loss 0.729 val_acc 0.811\n",
      "train_loss 0.112 val_loss 0.625 val_acc 0.839\n",
      "/home/ubuntu/models/sandwich/ft_resnet_loss_84.pth\n",
      "train_loss 0.092 val_loss 0.657 val_acc 0.840\n",
      "/home/ubuntu/models/sandwich/ft_resnet_loss_84.pth\n",
      "train_loss 0.078 val_loss 0.678 val_acc 0.842\n",
      "/home/ubuntu/models/sandwich/ft_resnet_loss_84.pth\n",
      "train_loss 0.066 val_loss 0.677 val_acc 0.836\n",
      "train_loss 0.062 val_loss 0.663 val_acc 0.842\n",
      "train_loss 0.061 val_loss 0.664 val_acc 0.848\n",
      "/home/ubuntu/models/sandwich/ft_resnet_loss_85.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0612638705319518"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_triangular_policy2(model, train_dl, valid_dl, max_lr=0.06, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
